{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biodiversity Conversation Analysis with Pol.is Math\n",
    "\n",
    "This notebook demonstrates a complete analysis of the biodiversity conversation using the Python implementation of Pol.is math. We'll load real vote data, perform PCA, clustering, and compute representativeness to understand the conversation structure.\n",
    "\n",
    "**Note:** This notebook uses the existing polismath modules that have been converted from Clojure to Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the parent directory to the path to import the polismath modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "# Import polismath modules\n",
    "from polismath.conversation.conversation import Conversation\n",
    "from polismath.math.named_matrix import NamedMatrix\n",
    "from polismath.math.pca import pca_project_named_matrix\n",
    "from polismath.math.clusters import cluster_named_matrix\n",
    "from polismath.math.repness import conv_repness, participant_stats\n",
    "from polismath.math.corr import compute_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Biodiversity Conversation Data\n",
    "\n",
    "We'll load the votes and comments from the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data files\n",
    "data_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', 'real_data/biodiversity'))\n",
    "votes_path = os.path.join(data_dir, '2025-03-18-2000-3atycmhmer-votes.csv')\n",
    "comments_path = os.path.join(data_dir, '2025-03-18-2000-3atycmhmer-comments.csv')\n",
    "\n",
    "# Load comments\n",
    "comments_df = pd.read_csv(comments_path)\n",
    "print(f\"Loaded {len(comments_df)} comments\")\n",
    "\n",
    "# Create a mapping of comment IDs to comment bodies\n",
    "comment_map = {}\n",
    "for _, row in comments_df.iterrows():\n",
    "    comment_id = str(row['comment-id'])\n",
    "    comment_body = row['comment-body']\n",
    "    moderated = row['moderated']\n",
    "    \n",
    "    # Only include moderated-in comments (value=1)\n",
    "    if moderated == 1:\n",
    "        comment_map[comment_id] = comment_body\n",
    "\n",
    "print(f\"There are {len(comment_map)} accepted comments in the conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_votes(votes_path):\n",
    "    \"\"\"Load votes from a CSV file into a format suitable for the Conversation class.\"\"\"\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(votes_path)\n",
    "    \n",
    "    # Convert to the format expected by the Conversation class\n",
    "    votes_list = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        pid = str(row['voter-id'])\n",
    "        tid = str(row['comment-id'])\n",
    "        \n",
    "        # Ensure vote value is a float (-1, 0, or 1)\n",
    "        try:\n",
    "            vote_val = float(row['vote'])\n",
    "            # Normalize to ensure only -1, 0, or 1\n",
    "            if vote_val > 0:\n",
    "                vote_val = 1.0\n",
    "            elif vote_val < 0:\n",
    "                vote_val = -1.0\n",
    "            else:\n",
    "                vote_val = 0.0\n",
    "        except ValueError:\n",
    "            # Handle text values\n",
    "            vote_text = str(row['vote']).lower()\n",
    "            if vote_text == 'agree':\n",
    "                vote_val = 1.0\n",
    "            elif vote_text == 'disagree':\n",
    "                vote_val = -1.0\n",
    "            else:\n",
    "                vote_val = 0.0  # Pass or unknown\n",
    "        \n",
    "        votes_list.append({\n",
    "            'pid': pid,\n",
    "            'tid': tid,\n",
    "            'vote': vote_val\n",
    "        })\n",
    "    \n",
    "    # Pack into the expected votes format\n",
    "    return {\n",
    "        'votes': votes_list\n",
    "    }\n",
    "\n",
    "# Load all votes\n",
    "votes = load_votes(votes_path)\n",
    "print(f\"Loaded {len(votes['votes'])} votes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize and Process the Conversation\n",
    "\n",
    "Now we'll create a Conversation object and process the votes to compute all the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversation object\n",
    "conv_id = 'biodiversity'\n",
    "conv = Conversation(conv_id)\n",
    "\n",
    "# Update with votes and recompute everything\n",
    "print(\"Processing votes and computing PCA, clusters, and representativeness...\")\n",
    "conv = conv.update_votes(votes, recompute=True)\n",
    "\n",
    "# Get conversation summary\n",
    "summary = conv.get_summary()\n",
    "print(\"\\nConversation Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's explore the data to better understand the conversation structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vote distribution\n",
    "vote_stats = conv.vote_stats\n",
    "\n",
    "labels = ['Agree', 'Disagree', 'Pass']\n",
    "values = [vote_stats['n_agree'], vote_stats['n_disagree'], vote_stats['n_pass']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, values, color=['green', 'red', 'gray'])\n",
    "plt.title('Vote Distribution')\n",
    "plt.ylabel('Number of Votes')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.1, str(v), ha='center')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at participation per comment\n",
    "comment_stats = {}\n",
    "for comment_id, stats in vote_stats['comment_stats'].items():\n",
    "    if comment_id in comment_map:  # Only include moderated-in comments\n",
    "        comment_stats[comment_id] = stats\n",
    "\n",
    "# Sort by total votes\n",
    "sorted_comments = sorted(comment_stats.items(), \n",
    "                         key=lambda x: x[1]['n_votes'], \n",
    "                         reverse=True)\n",
    "\n",
    "# Display top 10 most voted comments\n",
    "print(\"Top 10 Most Voted Comments:\")\n",
    "for comment_id, stats in sorted_comments[:10]:\n",
    "    print(f\"Comment {comment_id}: {stats['n_votes']} votes ({stats['n_agree']} agree, {stats['n_disagree']} disagree)\")\n",
    "    print(f\"  \\\"{comment_map[comment_id]}\\\"\")\n",
    "    print()\n",
    "\n",
    "# Visualize vote distribution for top comments\n",
    "top_comments = sorted_comments[:5]\n",
    "comment_ids = [c[0] for c in top_comments]\n",
    "agrees = [c[1]['n_agree'] for c in top_comments]\n",
    "disagrees = [c[1]['n_disagree'] for c in top_comments]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(comment_ids))\n",
    "\n",
    "plt.bar(x - width/2, agrees, width, label='Agrees', color='green')\n",
    "plt.bar(x + width/2, disagrees, width, label='Disagrees', color='red')\n",
    "\n",
    "plt.xlabel('Comment ID')\n",
    "plt.ylabel('Number of Votes')\n",
    "plt.title('Vote Distribution for Top 5 Most Voted Comments')\n",
    "plt.xticks(x, comment_ids)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PCA Visualization\n",
    "\n",
    "Let's visualize the PCA projection of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PCA projections\n",
    "proj_data = []\n",
    "for pid, coords in conv.proj.items():\n",
    "    # Find which group this participant belongs to\n",
    "    group_id = None\n",
    "    for group in conv.group_clusters:\n",
    "        if pid in group['members']:\n",
    "            group_id = group['id']\n",
    "            break\n",
    "    \n",
    "    proj_data.append({\n",
    "        'pid': pid,\n",
    "        'x': coords[0],\n",
    "        'y': coords[1],\n",
    "        'group': group_id\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "proj_df = pd.DataFrame(proj_data)\n",
    "\n",
    "# Plot PCA with clusters\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(data=proj_df, x='x', y='y', hue='group', palette='viridis', \n",
    "                alpha=0.7, s=50, edgecolor='w', linewidth=0.5)\n",
    "\n",
    "plt.title('PCA Projection of Participants with Cluster Assignments', fontsize=16)\n",
    "plt.xlabel('Principal Component 1', fontsize=14)\n",
    "plt.ylabel('Principal Component 2', fontsize=14)\n",
    "plt.grid(linestyle='--', alpha=0.3)\n",
    "plt.legend(title='Group ID', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add arrows to show the principal components\n",
    "pca_comps = conv.pca['comps']\n",
    "scale = 3  # Scale factor to make arrows visible\n",
    "\n",
    "# Add origin\n",
    "plt.scatter([0], [0], color='black', s=100, marker='x', linewidth=2)\n",
    "plt.text(0.1, 0.1, 'Origin', fontsize=12, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering Analysis\n",
    "\n",
    "Let's analyze the clusters that were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters\n",
    "print(f\"Number of clusters: {len(conv.group_clusters)}\")\n",
    "\n",
    "# Show sizes of each cluster\n",
    "for i, cluster in enumerate(conv.group_clusters):\n",
    "    print(f\"Cluster {cluster['id']}: {len(cluster['members'])} participants\")\n",
    "\n",
    "# Visualize cluster sizes\n",
    "cluster_sizes = [len(cluster['members']) for cluster in conv.group_clusters]\n",
    "cluster_ids = [cluster['id'] for cluster in conv.group_clusters]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(cluster_ids, cluster_sizes, color=sns.color_palette('viridis', len(cluster_ids)))\n",
    "plt.title('Size of Each Cluster')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of Participants')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Representative Comments Analysis\n",
    "\n",
    "Let's look at the most representative comments for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representative comments for each group\n",
    "if conv.repness and 'group_repness' in conv.repness:\n",
    "    print(\"Representative Comments by Group:\\n\")\n",
    "    \n",
    "    for group_id, repness_list in conv.repness['group_repness'].items():\n",
    "        print(f\"Group {group_id}:\")\n",
    "        print(f\"Size: {len([c for c in conv.group_clusters if c['id'] == int(group_id)][0]['members'])} participants\")\n",
    "        print(\"Top representative comments:\")\n",
    "        \n",
    "        # Sort by repness score (descending)\n",
    "        sorted_repness = sorted(repness_list, key=lambda x: abs(x['repness']), reverse=True)\n",
    "        \n",
    "        for i, rep in enumerate(sorted_repness[:5]):\n",
    "            comment_id = rep['tid']\n",
    "            score = rep['repness']\n",
    "            agree_ratio = rep['agree_ratio']\n",
    "            \n",
    "            # Get comment text\n",
    "            comment_text = comment_map.get(comment_id, \"[Comment not found]\")\n",
    "            \n",
    "            sentiment = \"Agreed with\" if score > 0 else \"Disagreed with\"\n",
    "            print(f\"  {i+1}. {sentiment} - Repness: {score:.3f}, Agree Ratio: {agree_ratio:.2f}\")\n",
    "            print(f\"     Comment {comment_id}: \\\"{comment_text}\\\"\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No representativeness data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Consensus Analysis\n",
    "\n",
    "Let's identify consensus comments that are widely agreed upon across all groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if consensus information is available\n",
    "if conv.repness and 'consensus_comments' in conv.repness:\n",
    "    consensus_comments = conv.repness['consensus_comments']\n",
    "    print(f\"Found {len(consensus_comments)} consensus comments across all groups:\\n\")\n",
    "    \n",
    "    for i, cons in enumerate(consensus_comments):\n",
    "        comment_id = cons['tid']\n",
    "        agree_ratio = cons['agree_ratio']\n",
    "        \n",
    "        # Get comment text\n",
    "        comment_text = comment_map.get(comment_id, \"[Comment not found]\")\n",
    "        \n",
    "        print(f\"{i+1}. Comment {comment_id}: \\\"{comment_text}\\\"\")\n",
    "        print(f\"   Agree Ratio: {agree_ratio:.2f}\")\n",
    "        print()\n",
    "else:\n",
    "    # Manually compute potential consensus comments\n",
    "    print(\"Computing potential consensus comments...\") \n",
    "    \n",
    "    # Get comment stats from vote_stats\n",
    "    consensus_threshold = 0.7  # Comments with agree_ratio > 0.7 across all groups\n",
    "    \n",
    "    potential_consensus = []\n",
    "    for comment_id, stats in vote_stats['comment_stats'].items():\n",
    "        if comment_id in comment_map and stats['n_votes'] > 10:  # Only consider comments with sufficient votes\n",
    "            agree_ratio = stats['n_agree'] / stats['n_votes']\n",
    "            if agree_ratio > consensus_threshold:\n",
    "                potential_consensus.append({\n",
    "                    'tid': comment_id,\n",
    "                    'agree_ratio': agree_ratio,\n",
    "                    'n_votes': stats['n_votes']\n",
    "                })\n",
    "    \n",
    "    # Sort by agree ratio (descending)\n",
    "    potential_consensus.sort(key=lambda x: x['agree_ratio'], reverse=True)\n",
    "    \n",
    "    print(f\"Found {len(potential_consensus)} potential consensus comments:\\n\")\n",
    "    \n",
    "    for i, cons in enumerate(potential_consensus[:10]):  # Show top 10\n",
    "        comment_id = cons['tid']\n",
    "        agree_ratio = cons['agree_ratio']\n",
    "        n_votes = cons['n_votes']\n",
    "        \n",
    "        # Get comment text\n",
    "        comment_text = comment_map.get(comment_id, \"[Comment not found]\")\n",
    "        \n",
    "        print(f\"{i+1}. Comment {comment_id}: \\\"{comment_text}\\\"\")\n",
    "        print(f\"   Agree Ratio: {agree_ratio:.2f}, Votes: {n_votes}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis\n",
    "\n",
    "Let's analyze correlations between comments to find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for a subset of the most voted comments\n",
    "top_comment_ids = [c[0] for c in sorted_comments[:15]]  # Top 15 most voted comments\n",
    "\n",
    "# Create a subset of the rating matrix\n",
    "subset_mat = conv.rating_mat.colname_subset(top_comment_ids)\n",
    "\n",
    "# Compute correlation\n",
    "corr_matrix = compute_correlation(subset_mat)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "corr_df = pd.DataFrame(corr_matrix, \n",
    "                       index=[comment_map[cid] for cid in top_comment_ids],\n",
    "                       columns=[comment_map[cid] for cid in top_comment_ids])\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Create mask for upper triangle\n",
    "heatmap = sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, \n",
    "                       mask=mask, fmt='.2f', linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Between Top Comments', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Group-Aware Consensus\n",
    "\n",
    "Let's identify comments that have high agreement across different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute agreement per group for each comment\n",
    "def compute_group_agreement(conv, comment_map):\n",
    "    results = []\n",
    "    \n",
    "    for comment_id in comment_map.keys():\n",
    "        group_agreements = []\n",
    "        \n",
    "        for group in conv.group_clusters:\n",
    "            group_id = group['id']\n",
    "            members = group['members']\n",
    "            \n",
    "            # Skip groups with too few members\n",
    "            if len(members) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Count votes from this group for this comment\n",
    "            agree_count = 0\n",
    "            disagree_count = 0\n",
    "            \n",
    "            for pid in members:\n",
    "                try:\n",
    "                    # Get row for participant\n",
    "                    row = conv.rating_mat.get_row_by_name(pid)\n",
    "                    # Get value for comment\n",
    "                    val = None\n",
    "                    try:\n",
    "                        col_idx = conv.rating_mat.colnames().index(comment_id)\n",
    "                        val = row[col_idx]\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "                        \n",
    "                    if val is not None and not np.isnan(val):\n",
    "                        if abs(val - 1.0) < 0.001:  # Close to 1 (agree)\n",
    "                            agree_count += 1\n",
    "                        elif abs(val + 1.0) < 0.001:  # Close to -1 (disagree)\n",
    "                            disagree_count += 1\n",
    "                except (KeyError, ValueError, TypeError):\n",
    "                    continue\n",
    "            \n",
    "            total_votes = agree_count + disagree_count\n",
    "            if total_votes > 0:\n",
    "                agree_ratio = agree_count / total_votes\n",
    "                group_agreements.append({\n",
    "                    'group_id': group_id,\n",
    "                    'agree_ratio': agree_ratio,\n",
    "                    'total_votes': total_votes\n",
    "                })\n",
    "        \n",
    "        # Only include comments with votes from at least 2 groups\n",
    "        if len(group_agreements) >= 2:\n",
    "            # Calculate metrics\n",
    "            agree_ratios = [g['agree_ratio'] for g in group_agreements]\n",
    "            min_agree = min(agree_ratios)\n",
    "            avg_agree = sum(agree_ratios) / len(agree_ratios)\n",
    "            agree_spread = max(agree_ratios) - min(agree_ratios)\n",
    "            \n",
    "            # Compute a consensus score\n",
    "            # High if average agreement is high and spread is low\n",
    "            consensus_score = avg_agree * (1 - agree_spread)\n",
    "            \n",
    "            results.append({\n",
    "                'tid': comment_id,\n",
    "                'text': comment_map[comment_id],\n",
    "                'groups': len(group_agreements),\n",
    "                'min_agree': min_agree,\n",
    "                'avg_agree': avg_agree,\n",
    "                'agree_spread': agree_spread,\n",
    "                'consensus_score': consensus_score,\n",
    "                'group_details': group_agreements\n",
    "            })\n",
    "    \n",
    "    # Sort by consensus score (descending)\n",
    "    results.sort(key=lambda x: x['consensus_score'], reverse=True)\n",
    "    return results\n",
    "\n",
    "# Compute group consensus\n",
    "group_consensus = compute_group_agreement(conv, comment_map)\n",
    "\n",
    "# Display top group consensus comments\n",
    "print(f\"Found {len(group_consensus)} comments with votes from multiple groups\")\n",
    "print(\"Top 10 Group Consensus Comments:\")\n",
    "for i, comment in enumerate(group_consensus[:10]):\n",
    "    print(f\"{i+1}. Comment {comment['tid']}: \\\"{comment['text']}\\\"\")\n",
    "    print(f\"   Consensus Score: {comment['consensus_score']:.3f}\")\n",
    "    print(f\"   Average Agreement: {comment['avg_agree']:.2f}, Agreement Spread: {comment['agree_spread']:.2f}\")\n",
    "    print(f\"   Groups: {comment['groups']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary of Findings\n",
    "\n",
    "Let's summarize our analysis of the biodiversity conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of findings\n",
    "print(\"Summary of Biodiversity Conversation Analysis:\")\n",
    "print(f\"\")\n",
    "print(f\"1. Conversation Volume:\")\n",
    "print(f\"   - {conv.participant_count} participants\")\n",
    "print(f\"   - {conv.comment_count} comments ({len(comment_map)} moderated in)\")\n",
    "print(f\"   - {vote_stats['n_votes']} total votes ({vote_stats['n_agree']} agree, {vote_stats['n_disagree']} disagree)\")\n",
    "print(f\"\")\n",
    "print(f\"2. Opinion Groups:\")\n",
    "print(f\"   - {len(conv.group_clusters)} distinct groups identified\")\n",
    "for i, cluster in enumerate(conv.group_clusters):\n",
    "    print(f\"   - Group {cluster['id']}: {len(cluster['members'])} participants ({len(cluster['members'])/conv.participant_count*100:.1f}%)\")\n",
    "print(f\"\")\n",
    "print(f\"3. Group Characterization:\")\n",
    "# Extract top agreed comments per group for a brief characterization\n",
    "if conv.repness and 'group_repness' in conv.repness:\n",
    "    for group_id, repness_list in conv.repness['group_repness'].items():\n",
    "        # Get top agree and disagree\n",
    "        agree_comments = [r for r in repness_list if r['repness'] > 0]\n",
    "        disagree_comments = [r for r in repness_list if r['repness'] < 0]\n",
    "        \n",
    "        # Sort by repness\n",
    "        agree_comments.sort(key=lambda x: x['repness'], reverse=True)\n",
    "        disagree_comments.sort(key=lambda x: abs(x['repness']), reverse=True)\n",
    "        \n",
    "        print(f\"   Group {group_id}:\")\n",
    "        if agree_comments:\n",
    "            top_agree = agree_comments[0]\n",
    "            comment_text = comment_map.get(top_agree['tid'], \"[Comment not found]\")\n",
    "            print(f\"   - Most agreed: \\\"{comment_text}\\\"\")\n",
    "        if disagree_comments:\n",
    "            top_disagree = disagree_comments[0]\n",
    "            comment_text = comment_map.get(top_disagree['tid'], \"[Comment not found]\")\n",
    "            print(f\"   - Most disagreed: \\\"{comment_text}\\\"\")\n",
    "print(f\"\")\n",
    "print(f\"4. Consensus:\")\n",
    "if group_consensus:\n",
    "    top_3 = group_consensus[:3]\n",
    "    for i, comment in enumerate(top_3):\n",
    "        print(f\"   {i+1}. \\\"{comment['text']}\\\"\")\n",
    "        print(f\"      Consensus Score: {comment['consensus_score']:.3f}, Avg Agreement: {comment['avg_agree']:.2f}\")\n",
    "print(f\"\")\n",
    "print(f\"5. Insights:\")\n",
    "print(f\"   - The conversation shows clear opinion groups with distinct perspectives\")\n",
    "print(f\"   - There are several areas of consensus across groups\")\n",
    "print(f\"   - The PCA analysis reveals that the first principal component primarily separates participants\")\n",
    "print(f\"     based on their views on environmental protection and biodiversity management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a complete analysis of the biodiversity conversation using the Python implementation of Pol.is math. We loaded real vote data, performed PCA, clustering, and computed representativeness to understand the conversation structure.\n",
    "\n",
    "The analysis revealed distinct opinion groups, representative comments for each group, and areas of consensus across the conversation. This demonstrates the effectiveness of the Pol.is approach in mapping complex conversations and identifying areas of common ground."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
